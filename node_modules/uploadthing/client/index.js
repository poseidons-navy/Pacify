import { contentDisposition, UploadThingError, safeParseJSON, resolveMaybeUrlArg, withExponentialBackoff } from '@uploadthing/shared';
export { generateClientDropzoneAccept, generateMimeTypes, generatePermittedFileTypes } from '@uploadthing/shared';

var version$1 = "6.9.0";

const maybeParseResponseXML = (maybeXml)=>{
    const codeMatch = maybeXml.match(/<Code>(.*?)<\/Code>/s);
    const messageMatch = maybeXml.match(/<Message>(.*?)<\/Message>/s);
    const code = codeMatch?.[1];
    const message = messageMatch?.[1];
    if (!code || !message) return null;
    return {
        code: s3CodeToUploadThingCode[code] ?? DEFAULT_ERROR_CODE,
        message
    };
};
/**
 * Map S3 error codes to UploadThing error codes
 *
 * This is a subset of the S3 error codes, based on what seemed most likely to
 * occur in uploadthing. For a full list of S3 error codes, see:
 * https://docs.aws.amazon.com/AmazonS3/latest/API/ErrorResponses.html
 */ const DEFAULT_ERROR_CODE = "UPLOAD_FAILED";
const s3CodeToUploadThingCode = {
    AccessDenied: "FORBIDDEN",
    EntityTooSmall: "TOO_SMALL",
    EntityTooLarge: "TOO_LARGE",
    ExpiredToken: "FORBIDDEN",
    IncorrectNumberOfFilesInPostRequest: "TOO_MANY_FILES",
    InternalError: "INTERNAL_SERVER_ERROR",
    KeyTooLongError: "KEY_TOO_LONG",
    MaxMessageLengthExceeded: "TOO_LARGE"
};

/**
 * Used by client uploads where progress is needed.
 * Uses XMLHttpRequest.
 */ async function uploadPartWithProgress(opts, retryCount = 0) {
    return new Promise((resolve, reject)=>{
        const xhr = new XMLHttpRequest();
        xhr.open("PUT", opts.url, true);
        xhr.setRequestHeader("Content-Type", opts.fileType);
        xhr.setRequestHeader("Content-Disposition", contentDisposition(opts.contentDisposition, opts.fileName));
        xhr.onload = async ()=>{
            if (xhr.status >= 200 && xhr.status < 300) {
                const etag = xhr.getResponseHeader("Etag");
                etag ? resolve(etag) : reject("NO ETAG");
            } else if (retryCount < opts.maxRetries) {
                // Add a delay before retrying (exponential backoff can be used)
                const delay = Math.pow(2, retryCount) * 1000;
                await new Promise((res)=>setTimeout(res, delay));
                resolve(await uploadPartWithProgress(opts, retryCount + 1)); // Retry the request
            } else {
                reject("Max retries exceeded");
            }
        };
        let lastProgress = 0;
        xhr.onerror = async ()=>{
            lastProgress = 0;
            if (retryCount < opts.maxRetries) {
                // Add a delay before retrying (exponential backoff can be used)
                const delay = Math.pow(2, retryCount) * 100;
                await new Promise((res)=>setTimeout(res, delay));
                await uploadPartWithProgress(opts, retryCount + 1); // Retry the request
            } else {
                reject("Max retries exceeded");
            }
        };
        xhr.upload.onprogress = (e)=>{
            const delta = e.loaded - lastProgress;
            lastProgress += delta;
            opts.onProgress(delta);
        };
        xhr.send(opts.chunk);
    });
}

const createAPIRequestUrl = (config)=>{
    const url = new URL(config.url);
    const queryParams = new URLSearchParams(url.search);
    queryParams.set("actionType", config.actionType);
    queryParams.set("slug", config.slug);
    url.search = queryParams.toString();
    return url;
};
/**
 * Creates a "client" for reporting events to the UploadThing server via the user's API endpoint.
 * Events are handled in "./handler.ts starting at L200"
 */ const createUTReporter = (cfg)=>{
    return async (type, payload)=>{
        const url = createAPIRequestUrl({
            url: cfg.url,
            slug: cfg.endpoint,
            actionType: type
        });
        let customHeaders = typeof cfg.headers === "function" ? cfg.headers() : cfg.headers;
        if (customHeaders instanceof Promise) customHeaders = await customHeaders;
        const response = await cfg.fetch(url, {
            method: "POST",
            body: JSON.stringify(payload),
            headers: {
                "Content-Type": "application/json",
                "x-uploadthing-package": cfg.package,
                "x-uploadthing-version": version$1,
                ...customHeaders
            }
        });
        switch(type){
            case "failure":
                {
                    // why isn't this narrowed automatically?
                    const p = payload;
                    const parsed = maybeParseResponseXML(p.s3Error ?? "");
                    if (parsed?.message) {
                        throw new UploadThingError({
                            code: parsed.code,
                            message: parsed.message
                        });
                    } else {
                        throw new UploadThingError({
                            code: "UPLOAD_FAILED",
                            message: `Failed to upload file ${p.fileName} to S3`,
                            cause: p.s3Error
                        });
                    }
                }
        }
        if (!response.ok) {
            const error = await UploadThingError.fromResponse(response);
            throw error;
        }
        const jsonOrError = await safeParseJSON(response);
        if (jsonOrError instanceof Error) {
            throw new UploadThingError({
                code: "BAD_REQUEST",
                message: jsonOrError.message,
                cause: response
            });
        }
        return jsonOrError;
    };
};

// Don't want to ship our logger to the client, keep size down
const version = version$1;
const uploadFilesInternal = async (endpoint, opts)=>{
    // Fine to use global fetch in browser
    const fetch = globalThis.fetch.bind(globalThis);
    const reportEventToUT = createUTReporter({
        endpoint: String(endpoint),
        url: opts.url,
        package: opts.package,
        fetch,
        headers: opts.headers
    });
    // Get presigned URL for S3 upload
    const s3ConnectionRes = await reportEventToUT("upload", {
        input: "input" in opts ? opts.input : null,
        files: opts.files.map((f)=>({
                name: f.name,
                size: f.size,
                type: f.type
            }))
    });
    if (!s3ConnectionRes || !Array.isArray(s3ConnectionRes)) {
        throw new UploadThingError({
            code: "BAD_REQUEST",
            message: "No URL. How did you even get here?",
            cause: s3ConnectionRes
        });
    }
    const fileUploadPromises = s3ConnectionRes.map(async (presigned)=>{
        const file = opts.files.find((f)=>f.name === presigned.fileName);
        if (!file) {
            console.error("No file found for presigned URL", presigned);
            throw new UploadThingError({
                code: "NOT_FOUND",
                message: "No file found for presigned URL",
                cause: `Expected file with name ${presigned.fileName} but got '${opts.files.join(",")}'`
            });
        }
        opts.onUploadBegin?.({
            file: file.name
        });
        if ("urls" in presigned) {
            await uploadMultipart(file, presigned, {
                reportEventToUT,
                ...opts
            });
            // wait a bit as it's unsreasonable to expect the server to be done by now
            await new Promise((r)=>setTimeout(r, 750));
        } else {
            await uploadPresignedPost(file, presigned, {
                reportEventToUT,
                ...opts
            });
        }
        let serverData = null;
        if (!opts.skipPolling) {
            serverData = await withExponentialBackoff(async ()=>{
                const res = await fetch(presigned.pollingUrl, {
                    headers: {
                        authorization: presigned.pollingJwt
                    }
                }).then((r)=>r.json());
                // eslint-disable-next-line @typescript-eslint/no-unsafe-return
                return res.status === "done" ? res.callbackData : undefined;
            });
        }
        return {
            name: file.name,
            size: file.size,
            type: file.type,
            key: presigned.key,
            url: "https://utfs.io/f/" + presigned.key,
            // eslint-disable-next-line @typescript-eslint/no-unsafe-assignment
            serverData: serverData,
            customId: presigned.customId
        };
    });
    return Promise.all(fileUploadPromises);
};
const genUploader = (initOpts)=>{
    return (endpoint, opts)=>// eslint-disable-next-line @typescript-eslint/no-unsafe-argument
        uploadFilesInternal(endpoint, {
            ...opts,
            url: resolveMaybeUrlArg(initOpts?.url),
            package: initOpts.package
        });
};
async function uploadMultipart(file, presigned, opts) {
    let etags;
    let uploadedBytes = 0;
    try {
        etags = await Promise.all(presigned.urls.map(async (url, index)=>{
            const offset = presigned.chunkSize * index;
            const end = Math.min(offset + presigned.chunkSize, file.size);
            const chunk = file.slice(offset, end);
            const etag = await uploadPartWithProgress({
                url,
                chunk: chunk,
                contentDisposition: presigned.contentDisposition,
                fileType: file.type,
                fileName: file.name,
                maxRetries: 10,
                onProgress: (delta)=>{
                    uploadedBytes += delta;
                    const percent = uploadedBytes / file.size * 100;
                    opts.onUploadProgress?.({
                        file: file.name,
                        progress: percent
                    });
                }
            });
            return {
                tag: etag,
                partNumber: index + 1
            };
        }));
    } catch (error) {
        await opts.reportEventToUT("failure", {
            fileKey: presigned.key,
            uploadId: presigned.uploadId,
            fileName: file.name,
            s3Error: error.toString()
        });
        throw "unreachable"; // failure event will throw for us
    }
    // Tell the server that the upload is complete
    await opts.reportEventToUT("multipart-complete", {
        uploadId: presigned.uploadId,
        fileKey: presigned.key,
        etags
    }).catch((res)=>{
        console.log("Failed to alert UT of upload completion");
        throw new UploadThingError({
            code: "UPLOAD_FAILED",
            message: "Failed to alert UT of upload completion",
            cause: res
        });
    });
}
async function uploadPresignedPost(file, presigned, opts) {
    const formData = new FormData();
    Object.entries(presigned.fields).forEach(([k, v])=>formData.append(k, v));
    formData.append("file", file); // File data **MUST GO LAST**
    const response = await new Promise((resolve, reject)=>{
        const xhr = new XMLHttpRequest();
        xhr.open("POST", presigned.url);
        xhr.setRequestHeader("Accept", "application/xml");
        xhr.upload.onprogress = (p)=>{
            opts.onUploadProgress?.({
                file: file.name,
                progress: p.loaded / p.total * 100
            });
        };
        xhr.onload = ()=>resolve({
                status: xhr.status
            });
        xhr.onerror = (e)=>reject(e);
        xhr.send(formData);
    }).catch(async (error)=>{
        await opts.reportEventToUT("failure", {
            fileKey: presigned.key,
            uploadId: null,
            fileName: file.name,
            s3Error: error.toString()
        });
        throw "unreachable"; // failure event will throw for us
    });
    if (response.status > 299 || response.status < 200) {
        await opts.reportEventToUT("failure", {
            fileKey: presigned.key,
            uploadId: null,
            fileName: file.name
        });
    }
}

export { genUploader, version };
